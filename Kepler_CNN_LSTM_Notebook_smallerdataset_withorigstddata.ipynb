{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "50000 train sequences\n",
      "10000 test sequences\n",
      "Build model...\n",
      "Train...\n",
      "Train on 5000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 20s - loss: 0.3269 - acc: 0.8698 - val_loss: 0.3295 - val_acc: 0.8810\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 19s - loss: 0.2946 - acc: 0.8886 - val_loss: 0.2833 - val_acc: 0.8830\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 19s - loss: 0.2792 - acc: 0.8976 - val_loss: 0.3119 - val_acc: 0.8740\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 19s - loss: 0.2763 - acc: 0.8952 - val_loss: 0.2741 - val_acc: 0.8820\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 19s - loss: 0.2656 - acc: 0.9000 - val_loss: 0.2802 - val_acc: 0.8840\n",
      "1000/1000 [==============================] - 0s     \n",
      "Test score: 0.280155418366\n",
      "Test accuracy: 0.884\n"
     ]
    }
   ],
   "source": [
    "'''Train a recurrent convolutional network on the IMDB sentiment\n",
    "classification task.\n",
    "GPU command:\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python kepler_cnn_lstm.py\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.datasets import imdb\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Embedding: Turn positive integers (indexes) into dense vectors of fixed size\n",
    "max_features = 5000\n",
    "maxlen = 100\n",
    "embedding_size = 128\n",
    "\n",
    "# Convolution\n",
    "filter_length = 3 #The extension (spatial or temporal) of each filter\n",
    "nb_filter = 64 #Number of convolution kernels to use (dimensionality of the output)\n",
    "pool_length = 2 # factor by which to downscale. 2 will halve the input.\n",
    "\n",
    "# LSTM\n",
    "lstm_output_size = 70\n",
    "\n",
    "# Training\n",
    "batch_size = 16 # # of samples used to compute the state, input at one time.\n",
    "nb_epoch = 5\n",
    "\n",
    "print('Loading data...')\n",
    "data_file1 = \"x-3d4hr_0210_training_nor.csv\"\n",
    "data_file2 = \"x-3d4hr_0210_testing_nor.csv\"\n",
    "data_file3 = \"y-3d4hr_0210_training.csv\"\n",
    "data_file4 = \"y-3d4hr_0210_testing.csv\"\n",
    "\n",
    "# data loading\n",
    "X_train = pd.read_csv(data_file1, delimiter=',', error_bad_lines=False, header=None)\n",
    "X_train = X_train.as_matrix()\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "y_train = pd.read_csv(data_file3, delimiter=',', error_bad_lines=False, header=None)\n",
    "y_train = y_train.as_matrix()\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_test = pd.read_csv(data_file2, delimiter=',', error_bad_lines=False, header=None)\n",
    "X_test = X_test.as_matrix()\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "y_test = pd.read_csv(data_file4, delimiter=',', error_bad_lines=False, header=None)\n",
    "y_test = y_test.as_matrix()\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "#print('Pad sequences (samples x time)')\n",
    "#X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "#X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "\n",
    "X_train = X_train[0:5000]\n",
    "y_train = y_train[0:5000]\n",
    "X_test  = X_test[0:1000]\n",
    "y_test  = y_test[0:1000]\n",
    "\n",
    "X_train = X_train*100\n",
    "X_test = X_test*100\n",
    "\n",
    "\n",
    "\n",
    "#print('X_train shape:', X_train.shape)\n",
    "#print('X_test shape:', X_test.shape)\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "#print(raw_input('123...'))\n",
    "\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_size, input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "model.add(MaxPooling1D(pool_length=pool_length))\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        border_mode='valid',\n",
    "                        activation='relu',\n",
    "                        subsample_length=1))\n",
    "model.add(MaxPooling1D(pool_length=pool_length))\n",
    "#Max pooling operation for temporal data\n",
    "#model.add(LSTM(lstm_output_size))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1)) #regular fully connected NN layer, the output dimension is one\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',  # configure the learning process after the model is built well.\n",
    "              optimizer='adam',\n",
    "              class_mode='binary')\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          validation_data=(X_test, y_test), show_accuracy=True)\n",
    "score, acc = model.evaluate(X_test, y_test, batch_size=batch_size,\n",
    "                            show_accuracy=True)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  0.,  1.,  1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(X_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  99.99320232,  100.00196666,  100.00573503,   99.99939731,\n",
       "        100.0462451 ,  100.05370573,  100.0386227 ,  100.0063631 ,\n",
       "         99.99611425,  100.02329225,  100.01448985,   99.9960286 ,\n",
       "        100.01307195,  100.02241677,   99.95535676,   99.96413061,\n",
       "        100.05481912,  100.03181868,   99.99127055,  100.08344357,\n",
       "        100.0009294 ,  100.05869217,   99.98541815,   99.96022901,\n",
       "         99.99853134,   99.97863316,   99.97153414,   99.97604478,\n",
       "         99.99384942,  100.01518453,   99.99999259,  100.05416251,\n",
       "        100.00839954,   99.9190433 ,   99.97488381,  100.06595296,\n",
       "         99.94797226,   99.9632361 ,   99.99342119,   99.90008721,\n",
       "        100.00780003,   99.96549142,   99.95748837,   99.97722478,\n",
       "         99.99229829,  100.02770773,   99.94730613,   99.96500609,\n",
       "        100.05354396,  100.0114447 ,  100.01637404,  100.07567842,\n",
       "        100.01047406,   99.94806742,  100.00701019,   99.9572124 ,\n",
       "         99.95241628,   99.96233207,   99.97904235,   99.93944583,\n",
       "         99.96078094,  100.00556375,   99.97602575,  100.00898003,\n",
       "         99.93213746,  100.01071196,   99.98782572,   99.93044359,\n",
       "        100.07918035,   99.99127055,  100.01923839,   99.99108974,\n",
       "        100.07473633,   99.99464877,  100.04026899,   99.97188624,\n",
       "        100.0460643 ,   99.99010007,  100.01522259,  100.06343119,\n",
       "        100.01086422,  100.04236253,  100.02530015,  100.01340502,\n",
       "        100.07073956,   99.9961428 ,   99.98454266,   99.99272652,\n",
       "         99.97141995,  100.00104359,   99.99071862,   99.99157507,\n",
       "         99.95016097,   99.97896622,   99.95280644,   99.97117253,\n",
       "        100.06198475,   99.97355156,  100.0573504 ,  100.06176588])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
